# Introduction

<?rfc toc="yes"?>
<?rfc symrefs="yes"?>
<?rfc sortrefs="yes"?>
<?rfc subcompact="no"?>
<?rfc compact="yes"?>
<?rfc comments="yes"?>

The fq_codel algorithm is a combined packet scheduler and AQM developed as part
of the anti-bufferbloat community effort. It is based on a modified Deficit
Round Robin (DRR) stochastic fairness queueing scheduler, with the CoDel AQM
algorithm operating on each sub-queue. This document describes the combined
algorithm; a reference implementation is included in the mainline Linux kernel
as the fq_codel queueing discipline.

The rest of this document is structured as follows: The rest of this section
gives some concepts and terminology used in the rest of the document, and gives
a short informal summary of the fq_codel algorithm. Section 2 (FIXME: automatic
internal links?) gives an overview of the CoDel algorithm. Section 3 defines the
parameters and data structures employed by fq_codel and section 4 describes the
working of the algorithm in detail. Section 6 describes security considerations
while section 8 concludes.

## Terminology and concepts
Queue: A queue of packets represented internally in fq_codel.

Scheduler: A mechanism to select which queue a packet is dequeued from.

CoDel AQM: The Active Queue Management algorithm employed by fq_codel; an
overview of CoDel is given in section 2.

DRR: Deficit round-robin scheduling.

## Informal summary of fq_codel
FQ_Codel is a *hybrid* of DRR and Codel, with an optimization for
sparse flows similar to SQF. We call this "Flow Queuing" as it is
*unfair* to flows that build a queue.

FQ_Codel uses a stochastic model to classify incoming packets into
different flows and is used to provide a fair share of the bandwidth
to all the flow building flows using the queue. Each such flow is
managed by the CoDel queuing discipline.  Packet ordering within a flow is
preserved since it uses FIFO queues internally.

Fq_codel is an implementation of a somewhat modified stochastic fairness
queueing algorithm, with CoDel added as an AQM for the individual queues. As
such, it consists of two parts: the scheduler which selects which queue to
dequeue a packet from, and the CoDel AQM which works on each of the queues built
in to the qdisc. The subtleties of fq_codel are mostly in the scheduling part,
which is the subject of this description. For a description of CoDel, refer to
Kathy and Van's paper[1].

The interaction between the scheduler and the CoDel algorithm are fairly
straight forward: At initiation (i.e. at boot, or when fq_codel is first
installed on the interface, or its parameters are changed), the list of queues
is initialised so that each queue has a separate set of CoDel state variables.
By default, 1024 queues are created, and packets are hashed into them at enqueue
time. Each queue maintains the CoDel state variables throughout its lifetime,
and so acts the same as the non-fq CoDel variant would (including retaining the
control law state when the queue drains, etc).

The new/old queue distinction has a particular consequence for queues that don't
build up more than a quantum bytes before being visited by the scheduler (as a
new queue), *and* then stay empty until the scheduler comes back around to it in
the list of old queues: Such queues will get removed from the list, and then
re-added as a new queue each time a packet arrives for it, and so will always
get priority over queues that do not empty out each round. Exactly how much data
a flow has to send to keep its queue in this state is somewhat difficult to
reason about, because it depends on both the egress link speed and the number of
concurrent flows. This makes it harder to reason about the behaviour of
fq_codel. However, in practice many things that are beneficial to have
prioritised for typical internet use (ACKs, DNS lookups, interactive SSH, HTTP
requests; and also ICMP pings) *tend* to fall in this category, which is why
fq_codel performs so well for many practical applications.


# CoDel
CoDel is described in the LWN article, the ACM Queue paper, the CACM
article, and Van Jacobson's IETF presentation. The basic idea is to
control queue length, maintaining sufficient queueing to keep the
outgoing link busy, but avoiding building up the queue beyond that
point. This is done by preferentially dropping packets that remain in
the queue for “too long”.

When each new packet arrives, it is marked with its arrival
time. Later, when it is that packet's turn to be dequeued, CoDel
computes its sojourn time (the current time minus the arrival
time). If the sojourn time for packets being dequeued exceeds the
target time for a time period of at least interval, a packet will be
dropped (or marked, if ECN is enabled) in order to signal the source
endpoint to reduce its send rate. If the sojourn still remains above
the target time, additional packet drops will occur on a schedule
computed from an inverse-square-root control law until either (1) the
queue becomes empty or (2) a packet is encountered with a sojourn time
that is less than the target time. This target time, is normally set
to about five milliseconds, and the interval is normally set to about
100 milliseconds. This approach has proven to be quite effective in a
wide variety of situations.


# Parameters and data structures
## Parameters
### Interval

The interval has the same semantics as codel and is used to ensure
that the measured minimum delay does not become too stale.  The
minimum delay must be experienced in the last epoch of length
interval.  It should be set on the order of the worst-case RTT through
the bottleneck to give end‐points sufficient time to react.

Default interval value is 100ms.

### Target

The target has the same semantics as ()[codel] and is the acceptable
minimum standing/persistent queue delay. This minimum delay is
identified by tracking the local minimum queue delay that packets
experience.

Default target value is 5ms.

### Packet limit

Embedded systems such as home routers do not have infinite memory, so some
packet limit must be enforced.
The packet limit has the same semantics as codel and is the hard limit
on the real queue size.  When this limit is reached, incoming packets
from the largest queue (measured in bytes) are dropped from the head
of the flow.

Default packet limit is 10240 packets.

### Quantum

The quantum is the number of bytes used as 'deficit' in the flow
queuing algorithm. Default is set to 1514 bytes which corresponds to
the Ethernet MTU plus the hardware header length of 14 bytes.

### Flows

The flows is the number of flows into which the incoming packets are
classified. Due to the stochastic nature of hashing, multiple flows
may end up being hashed into the same slot. FIXME: "Newer flows have priority
over older ones."

This parameter can be set only at load time since memory has to be
allocated for the hash table in the current implementation.
Default value is 1024.

### ECN

ECN is *enabled* by default. Rather than do anything special with
misbehaved ECN flows, FQ_CoDel relies on the packet scheduling system
to minimize their impact, thus unresponsive packets in a flow being
marked with ECN can grow to the overall packet limit, but will not
otherwise affect the performance of the system.

## Data structures
### Internal sub-queues
Holds packets, has CoDel data structure.

Queue space is shared: there's a global limit on the number of packets the
queues can hold, but not one per queue. If the space runs out at enqueue time,
the queue with the largest number of *bytes* in it will get a packet dropped.
This means that the packet being enqueued will pretty much never be dropped;
rather a different packet is dropped, and not necessarily from the same queue.
Packets are always dropped from the head of a queue.


### New and old flows lists

fq_codel maintains two lists of active queues, called "new" and "old" queues
("new" and "old" being the terms used in the code). When a packet is added to a
queue that is not currently active, that queue is added to the list of new
queues. This is the source of some subtlety in the packet scheduling at dequeue
time, explained below.

# The fq_codel scheduler

## The DRR mechanism

fq_codel is byte-based, employing a deficit round-robin mechanism[3] between
queues. The quantum is configurable, but defaults to the interface MTU. This
means that if one flow sends packets of size MTU/3, and another sends MTU-sized
packets, the first flow will dequeue three packets each time it gets a turn,
whereas the second flow only dequeues one. This is kept track of by maintaining
a byte dequeue deficit for each queue, which is first initialised to the quantum
value, and decreased by the packet size on each dequeue from the queue.



## Enqueue
- Packet timestamping
- Flow hashing
- Packet dropping on full queue
- Byte backlog and deficit accounting

## Dequeue

Most of fq_codel's scheduling is done at packet dequeue time. It consists of
three parts: selecting a queue from which to dequeue a packet, actually
dequeuing it (employing the CoDel algorithm in the process), and some final
bookkeeping.

For the first part, the scheduler first looks at the list of new queues; for
each queue in that list, if that queue has a negative deficit (i.e. it has
already dequeued a quantum of bytes (or more)), its deficit is increased by one
quantum, and the queue is put onto the end of the list of old queues, and the
routine starts again. Otherwise, that queue is selected for dequeue. If the list
of new queues is empty, the scheduler proceeds down the list of old queues in
the same fashion (checking the deficit, and either selecting the queue for
dequeuing, or increasing the deficit and putting the queue back at the end of
the list).

After having selected a queue from which to dequeue a packet, the CoDel
algorithm is invoked on that queue. This applies the CoDel control law in the
usual fashion, and may discard one or more packets from the head of the queue,
before returning the packet that should be dequeued (or nothing if the queue is
or becomes empty while being handled by the CoDel algorithm).

Finally, if the CoDel algorithm did not return a packet, the queue is empty, and
the scheduler does one of two things: if the queue selected for dequeue came
from the list of new queues, it is moved to the end of the list of old queues.
If instead it came from the list of old queues, that queue is removed from the
list, to be added back (as a new queue) the next time a packet arrives that
hashes to that queue. Then, (since no packet was available for dequeue), the
whole dequeue process is restarted from the beginning.

If, instead, the scheduler *did* get a packet back from the CoDel algorithm, it
updates the byte deficit for the selected queue before returning the packet to
the lower layers of the kernel networking stack for sending.


# Implementation considerations

# Resources and Additional Information

# Security Considerations

This document describes an hybrid packet scheduling and active queue
management algorithm for implementation in networked devices. There
are no specific security exposures associated with FQ_CoDel. Some
exposures present in current FIFO systems are in fact reduced
(e.g. simple minded packet floods).

FIXME: temporary starvation when many new flows appear?


# IANA Considerations
This document has no actions for IANA.

# Acknowlegements

# Conclusions

FQ_CoDel is a very general, efficient, nearly parameterless active queue
management approach combining flow queuing with CoDel. It is a critical tool in
solving bufferbloat. FQ_CoDel's settings MAY be modified for other
special-purpose networking applications.

On-going projects are: improving fq_codel with more SFQ-like behavior
for lower bandwidth systems
[NFQCODEL](http://www.bufferbloat.net/projects/cerowrt/wiki/nfq_codel).
ns2 and ns3 models are available.
